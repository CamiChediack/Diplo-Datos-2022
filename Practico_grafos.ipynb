{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49e9927-f016-4660-89df-26c5800aea8b",
   "metadata": {},
   "source": [
    "# Práctico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2ae9e-6076-4a12-931c-5349ee7eb2d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "El trabajo práctico de la materia consiste en el análisis de un conjunto de datos extraído de Twitter. La idea es emplear los conceptos de grafos vistos en clase sobre un caso real de actualidad.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "El dataset consiste en un conjunto de hilos de tweets, con un total de ~150000 tweets, extraídos entre Enero y Marzo de 2021. La temática de los mismos está referida a la vacunación contra el covid-19 en Argentina.\n",
    "\n",
    "Pueden descargar el dataset del siguiente [link](https://drive.google.com/file/d/1X_qKsE8muAnom2tDX4sLlmBAO0Ikfe_G/view?usp=sharing).\n",
    "\n",
    "### Campos\n",
    "\n",
    "- **created_at:** Fecha del tweet\n",
    "- **id_str:** ID del tweet\n",
    "- **full_text:** Contenido del tweet\n",
    "- **in_reply_to_status_id:** ID del tweet inmediatamente anterior en el hilo\n",
    "- **in_reply_to_user_id:** Autor del tweet inmediatamente anterior en el hilo\n",
    "- **user.id:** Autor del tweet\n",
    "- **user_retweeters:** Lista de ID de usuarios que retweetearon el tweet\n",
    "- **sentiment:** Etiquetado manual que indica el sentimiento o intención del tweet con respecto al tweet anterior en el hilo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72860bf6",
   "metadata": {},
   "source": [
    "Ejemplo\n",
    "\n",
    "<img src=\"./figuras/twitter-thread.jpg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed8c8b-8c40-4d18-b4ad-c853e1c3b7d1",
   "metadata": {},
   "source": [
    "## Configuración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c83a7-0c4e-4bff-b8cb-253671e5d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "## Descargar el csv con los datos en este directorio\n",
    "DATA_DIR = Path('~/Descargas')\n",
    "INPUT_FILE = DATA_DIR / 'vacunas.csv'\n",
    "\n",
    "## Creamos el directorio en caso de que no exista\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6889f-86be-4fc8-b281-a738b8d475c4",
   "metadata": {},
   "source": [
    "### Cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43cef47-be3b-47ba-9a07-9373013580ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'id_str': str,\n",
    "    'full_text': str,\n",
    "    'in_reply_to_status_id': str,\n",
    "    'in_reply_to_user_id': str,\n",
    "    'user.id': str\n",
    "}\n",
    "df = pd.read_csv(INPUT_FILE, dtype=dtypes).dropna(subset=['user_retweeters'])\n",
    "df['user_retweeters'] = df['user_retweeters'].apply(lambda x: [str(elem) for elem in eval(x)])\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd778ff2-c52b-4541-83bb-ab515e233fb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Observamos algunos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626fb5fa-2875-47c0-9e30-cb1a456a1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print('Texto:', df.full_text.values[idx])\n",
    "print('Retweets:', len(df.user_retweeters.values[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca9ab4-d966-4613-8d06-b139b30255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 376\n",
    "print('Text:', df.full_text.values[idx])\n",
    "print('Retweets:', len(df.user_retweeters.values[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3911d7-cc49-4d84-95b6-4f096f5f56c3",
   "metadata": {},
   "source": [
    "### Calculamos la cantidad de hilos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6c11f-5766-45e4-a264-f3733df8694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = df[df['in_reply_to_user_id'].isna()]\n",
    "roots.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258ad30-e325-45ce-94e8-9e0ec4317df4",
   "metadata": {},
   "source": [
    "## Actividades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f377d2-6e8d-437c-ab01-1a314b7af7eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Primera parte\n",
    "\n",
    "#### **1. Construcción del grafo** \n",
    "\n",
    "Construir el **grafo de retweets**, definido de la siguiente manera:\n",
    "\n",
    "- Tipo de grafo: Dirigido\n",
    "- Nodos: ID de los usuarios\n",
    "- Enlaces: (Usuario A) ---> (Usuario B) si B retweeteó algún tweet de A\n",
    "\n",
    "Con estos datos, el grafo debería tener alrededor de 40000 nodos y 90000 enlaces.\n",
    "\n",
    "Considerar la versión no dirigida del grafo y estudiar su conectividad. Si existe una única \"componente gigante\", realizar el resto de las actividades sobre ella, en lugar de sobre el grafo completo.\n",
    "\n",
    "Calcular las siguientes métricas globales del grafo:\n",
    "\n",
    "- Grado medio\n",
    "- Asortatividad\n",
    "- Transitividad\n",
    "- Coeficiente de clustering de Watts-Strogatz\n",
    "\n",
    "**Opcional:** Comparar las métricas calculadas anteriormente con las de un grafo aleatorio con la misma distribución de grado. Pueden utilizar para ello este [método](https://networkx.org/documentation/stable/reference/generated/networkx.generators.degree_seq.configuration_model.html?highlight=configuration#networkx.generators.degree_seq.configuration_model). Con esto en mente, comentar si los valores obtenidos anteriormente difieren significativamente del caso aleatorio.\n",
    "\n",
    "\n",
    "#### **2. Centralidad**\n",
    "\n",
    "Calcular 5 métricas de centralidad de nodos. Graficar la distribución de cada una de ellas ¿Existe alguna correlación entre las distintas centralidades?\n",
    "\n",
    "Hacer un ranking con los 10 nodos más centrales para cada métrica. ¿Hay coincidencia entre los rankings?. ¿Qué características tienen los usuarios más centrales y sus respectivos tweets?\n",
    "\n",
    "**Opcional:** Determinar si existe alguna correlación entre la centralidad de un nodo y su actividad en red social. Es decir, evaluar si los usuarios que más escriben son los más centrales o no.\n",
    "\n",
    "**Observación:** El cálculo de centralidad puede ser costoso, por lo que es recomendable utilizar alguna librería más eficiente que `networkx`. La más simple de usar es `igraph` (ver [documentación](https://igraph.readthedocs.io/en/stable/)). En particular, resulta práctico utilizar el método `igraph.Graph().from_networkx()`, para convertir fácilmente un grafo de `networkx` a `igraph`.\n",
    "\n",
    "#### **3. Comunidades**\n",
    "\n",
    "Utilizar el algoritmo de Louvain con el parámetro \"resolución\" igual a 1. Caracterizar las comunidades halladas (cantidad, distribución de tamaños). Utilizar la modularidad y otras dos métricas a elección para evaluar la calidad de la partición encontrada. \n",
    "\n",
    "Variar el parámetro \"resolución\" y observar cómo cambia la distribución de comunidades encontradas. ¿Existe algún valor para el cual se identifiquen dos grandes comunidades?\n",
    "\n",
    "Elegir otro algoritmo de detección de comunidades y comparar los resultados con los obtenidos anteriormente.\n",
    "\n",
    "**Opcional:** Correr el algoritmo de Louvain con distintas semillas aleatorias. Utilizar alguna métrica de comparación externa entre las particiones obtenidas para determinar en qué medida depende el algoritmo de la condición inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e39e1-9b78-4b44-9743-604bf0ca5a3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Segunda parte\n",
    "\n",
    "### **4. Extracción de etiquetas**\n",
    "\n",
    "En el archivo [etiquetas.csv](https://drive.google.com/file/d/1LWY3VoIRt0xKwEbbtMXYePOGZvgPsQh-/view?usp=sharing) están las etiquetas para un pequeño subconjunto de nodos. Podemos interpretar el valor de la etiqueta como la pertenencia a una determinada clase, donde los usuarios de una misma clase en general tienden a expresar apoyo entre sí.\n",
    "\n",
    "- Determinar quiénes son los usuarios referentes de cada clase (utilizar alguna medida de centralidad calculada sobre el grafo de retweets).\n",
    "- Utiliando los resultados del práctico anterior, determinar si los usuarios de cada clase forman parte de distintas comunidades.\n",
    "\n",
    "**Opcional:** Reconstruir el archivo \"etiquetas.csv\". Para eso, hacer lo siguiente\n",
    "\n",
    "- Construir un grafo en donde los nodos sean usuarios, y donde los enlaces unan dos nodos si entre ellos hubo más respuestas de apoyo que de oposición.\n",
    "- Extraer las dos componentes más grandes del grafo. Esos serán nuestros nodos etiquetados.\n",
    "\n",
    "### **5. Embedding de nodos**\n",
    "\n",
    "- Generar un embedding del grafo de retweets utilizando el algoritmo `word2vec`.\n",
    "- Reducir a 2 la dimensionalidad del embedding utilizando [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.htmlhttps://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) y [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.htmlhttps://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n",
    "- Graficar los embeddings correspondientes a los datos etiquetados. ¿Es posible diferenciar unos de otros?\n",
    "\n",
    "**Opcional:** Graficar además los embeddings de los nodos que forman parte de las comunidades asociadas a cada clase. Determinar si el embedding permite distinguir cada comunidad.\n",
    "\n",
    "### **Opcional: 6. Redes neuronales de grafos**\n",
    "\n",
    "El archivo [word_vectors.csv](https://drive.google.com/file/d/1aoxugyMktKb0NQ8Pf3bdhKvh8BAj7YZz/view?usp=sharing) contiene un embedding de 300 dimensiones para cada tweet, otenido utilizando un modelo preentrenado de [FastText](https://fasttext.cc/). Construir una matriz de features para los nodos tomando, para cada usuario, el promedio de los vectores correspondientes a los tweets que escribió. Utilizando estos features, y tomando como ejemplos etiquetados los usuarios de \"etiquetas.csv\" entrenar una red neuronal de grafos para realizar una clasificación binaria sobre el resto de los nodos. Pueden utilizar como base el siguiente modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5333b57-a167-46a6-af83-95d1960921d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(dataset.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.classifier = Linear(2, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Embedding final\n",
    "        \n",
    "        # Aplicamos un clasificador lineal sobre el embedding\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c67f8-f2aa-4b95-8f0a-9a6c8f28b221",
   "metadata": {},
   "source": [
    "**Observación:** para alimentar la red neuronal, es necesario construir un objeto de la clase `Dataset` de PyTorch-Geometric. Una forma de hacer eso es la siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2f06b-eb86-4970-ba98-618267618521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "## Reemplazar por el grafo correspondiente\n",
    "g = nx.Graph()\n",
    "\n",
    "## Etiquetas. Reemplazar por las clases del archivo 'etiquetas.csv'.\n",
    "## Asignar la clase '2' a los ejemplos no etiquetados\n",
    "labels = [1, 0, 2, ..., 1]\n",
    "\n",
    "## True si el ejemplo está etiquetado (clases 0 y 1)\n",
    "train_idx = [True, True, False, ..., True]\n",
    "\n",
    "## Matriz de features (word vectors)\n",
    "features = ...\n",
    "\n",
    "adj = nx.to_scipy_sparse_matrix(g).tocoo()\n",
    "row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
    "col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
    "edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "\n",
    "class TwitterDataset(InMemoryDataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super(TwitterDataset, self).__init__('.', transform, None, None)\n",
    "\n",
    "        data = Data(edge_index=edge_index)\n",
    "        \n",
    "        data.num_nodes = g.number_of_nodes()\n",
    "        \n",
    "        # Features \n",
    "        data.x = torch.from_numpy(features).type(torch.float32)\n",
    "        \n",
    "        # Etiquetas\n",
    "        y = torch.from_numpy(labels).type(torch.long)\n",
    "        data.y = y.clone().detach()\n",
    "        \n",
    "        data.num_classes = 2\n",
    "        \n",
    "        n_nodes = g.number_of_nodes()\n",
    "        \n",
    "        # create train and test masks for data\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[train_idx] = True\n",
    "        data['train_mask'] = train_mask\n",
    "\n",
    "        self.data, self.slices = self.collate([data])\n",
    "\n",
    "    def _download(self):\n",
    "        return\n",
    "\n",
    "    def _process(self):\n",
    "        return\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc943a",
   "metadata": {},
   "source": [
    "## Ejercicio 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph = df[['user_retweeters', 'user.id']]\n",
    "_graph = _graph[_graph['user_retweeters'].apply(lambda x: len(x)) > 0]\n",
    "_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph = pd.merge(_graph, pd.DataFrame(_graph['user_retweeters'].values.tolist()).add_prefix('rt_'), on=_graph.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph = _graph.drop(columns = ['key_0', 'user_retweeters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph = pd.melt(_graph, id_vars = ['user.id'], var_name = 'rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph = _graph.drop(columns = 'rt')\n",
    "_graph = _graph.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = zip(_graph['user.id'], _graph['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c043d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añadir nodos\n",
    "G.add_nodes_from(_graph['user.id'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añadir enlaces/aristas\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "print(f'Cantidad de nodos: {n}')\n",
    "print(f'Cantidad de links: {m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ca049",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.Graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = G1.number_of_nodes()\n",
    "m1 = G1.number_of_edges()\n",
    "print(f'Cantidad de nodos: {n1}')\n",
    "print(f'Cantidad de links: {m1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3afaf88",
   "metadata": {},
   "source": [
    "### Matriz de Adyacencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(G1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
